{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb_nlp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a906c7aeb6148f499824b4e764cebc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1c13cbcfb6c54b789779707d7a40fedb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_75e8898d88754091841c356a7db5a923",
              "IPY_MODEL_d698aebe70134fd196d34d1a2e9bc9af"
            ]
          }
        },
        "1c13cbcfb6c54b789779707d7a40fedb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75e8898d88754091841c356a7db5a923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6af588fbe5ad4e7aaa7f78444bf01ab4",
            "_dom_classes": [],
            "description": "Epoch 1 - train:  44%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 6250,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2720,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f866b4389034af5ae0e72fb133e9fdb"
          }
        },
        "d698aebe70134fd196d34d1a2e9bc9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f936760ef19145e69b47134698a34ad8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2720/6250 [03:16&lt;04:16, 13.75it/s, train loss=0.427, train accuracy=0.816]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6fd4f11af5c542d79188da351a69c657"
          }
        },
        "6af588fbe5ad4e7aaa7f78444bf01ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f866b4389034af5ae0e72fb133e9fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f936760ef19145e69b47134698a34ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6fd4f11af5c542d79188da351a69c657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOQq19OweMlZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3ff4aeb-fd32-433b-c202-acef79fbb431"
      },
      "source": [
        "%tensorflow_version 1.x\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbBBNbEIfuVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import collections\n",
        "import hashlib\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from tempfile import gettempdir\n",
        "import zipfile\n",
        "import pickle\n",
        "import numpy as np\n",
        "from six.moves import urllib\n",
        "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.contrib.tensorboard.plugins import projector\n",
        "\n",
        "data_index = 0\n",
        "\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzil4zvzfwjU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "c3173f67-0c46-4b36-abf3-985f4e9f8657"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02\" -O imdb.csv\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-19 01:35:31--  https://docs.google.com/uc?export=download&confirm=&id=1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.203.139, 74.125.203.102, 74.125.203.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.203.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-00-1k-docs.googleusercontent.com/docs/securesc/jmhctunv9qd75m91b3g2ql5qjatrq53u/jif28qqeubdp4a1q4du8467j7bi0cbqh/1600479300000/00519734162681609028/09820975160179898913Z/1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02?e=download [following]\n",
            "--2020-09-19 01:35:36--  https://doc-00-1k-docs.googleusercontent.com/docs/securesc/jmhctunv9qd75m91b3g2ql5qjatrq53u/jif28qqeubdp4a1q4du8467j7bi0cbqh/1600479300000/00519734162681609028/09820975160179898913Z/1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02?e=download\n",
            "Resolving doc-00-1k-docs.googleusercontent.com (doc-00-1k-docs.googleusercontent.com)... 74.125.204.132, 2404:6800:4008:c04::84\n",
            "Connecting to doc-00-1k-docs.googleusercontent.com (doc-00-1k-docs.googleusercontent.com)|74.125.204.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=ldsnv49ptru46&continue=https://doc-00-1k-docs.googleusercontent.com/docs/securesc/jmhctunv9qd75m91b3g2ql5qjatrq53u/jif28qqeubdp4a1q4du8467j7bi0cbqh/1600479300000/00519734162681609028/09820975160179898913Z/1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02?e%3Ddownload&hash=loku5efrc243sefup6fdiplslvvt04c6 [following]\n",
            "--2020-09-19 01:35:36--  https://docs.google.com/nonceSigner?nonce=ldsnv49ptru46&continue=https://doc-00-1k-docs.googleusercontent.com/docs/securesc/jmhctunv9qd75m91b3g2ql5qjatrq53u/jif28qqeubdp4a1q4du8467j7bi0cbqh/1600479300000/00519734162681609028/09820975160179898913Z/1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02?e%3Ddownload&hash=loku5efrc243sefup6fdiplslvvt04c6\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.203.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-00-1k-docs.googleusercontent.com/docs/securesc/jmhctunv9qd75m91b3g2ql5qjatrq53u/jif28qqeubdp4a1q4du8467j7bi0cbqh/1600479300000/00519734162681609028/09820975160179898913Z/1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02?e=download&nonce=ldsnv49ptru46&user=09820975160179898913Z&hash=9lb0pj8rdr2nkca85lon3mq2bh5kk53f [following]\n",
            "--2020-09-19 01:35:36--  https://doc-00-1k-docs.googleusercontent.com/docs/securesc/jmhctunv9qd75m91b3g2ql5qjatrq53u/jif28qqeubdp4a1q4du8467j7bi0cbqh/1600479300000/00519734162681609028/09820975160179898913Z/1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02?e=download&nonce=ldsnv49ptru46&user=09820975160179898913Z&hash=9lb0pj8rdr2nkca85lon3mq2bh5kk53f\n",
            "Connecting to doc-00-1k-docs.googleusercontent.com (doc-00-1k-docs.googleusercontent.com)|74.125.204.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘imdb.csv’\n",
            "\n",
            "imdb.csv                [   <=>              ]  63.14M   109MB/s    in 0.6s    \n",
            "\n",
            "2020-09-19 01:35:37 (109 MB/s) - ‘imdb.csv’ saved [66212309]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr63Ln1hgqO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "dados = pd.read_csv('imdb.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIcmWtO2hmCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c8d7f372-3356-4034-d48b-f06f30b65a7a"
      },
      "source": [
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nPqL4zshnMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokens(data): #utilizado para separar as frases em palavras separadas\n",
        "    ret = []\n",
        "    for s in data.iterrows():\n",
        "        ret +=s[1][0].split()\n",
        "    return ret\n",
        "\n",
        "def build_dataset(words, n_words): #criar o dataset em tensorflow\n",
        "    count = [['UNK', -1]]\n",
        "    count.extend(collections.Counter(words).most_common(n_words - 1)) #pega as n_words mais comuns, evita entao ter palavras bizarras\n",
        "    dictionary = {word: index for index, (word, _) in enumerate(count)} #dicionario para fazer a conversao de int - palavra\n",
        "    data = []\n",
        "    unk_count = 0\n",
        "    for word in words:\n",
        "      index = dictionary.get(word, 0)\n",
        "      if index == 0:  # dictionary['UNK']\n",
        "        unk_count += 1\n",
        "      data.append(index)\n",
        "    count[0][1] = unk_count\n",
        "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
        "    return data, count, dictionary, reversed_dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFNlrQJDhwRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = 40000\n",
        "fix_break = lambda x: x.replace(\"<br />\",\" <br/> \")\n",
        "fix_dots = lambda x: x.replace(\".\",\" . \")\n",
        "fix_comma = lambda x: x.replace(\",\",\" , \")\n",
        "fix_brackets1 = lambda x: x.replace(\"(\",\" ( \")\n",
        "fix_brackets2 = lambda x: x.replace(\")\",\" ) \")\n",
        "fix_dash = lambda x: x.replace(\"-\",\" - \")     \n",
        "fix_excl = lambda x: x.replace(\"!\",\" ! \")     \n",
        "dados.review = dados.review.apply(fix_break)\n",
        "dados.review = dados.review.apply(fix_dots)\n",
        "dados.review = dados.review.apply(fix_comma)\n",
        "dados.review = dados.review.apply(fix_brackets1)\n",
        "dados.review = dados.review.apply(fix_brackets2)\n",
        "dados.review = dados.review.apply(fix_excl)\n",
        "dados.review = dados.review.apply(fix_dash)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuOntERtiW_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok = tokens(dados)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkGjZfr2icyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data, count, unused_dictionary, reverse_dictionary = build_dataset(tok, vocabulary_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0Z2Kb_vjKuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(batch_size, num_skips, skip_window): #gera a batch para um formato que o tensorflow entende\n",
        "    global data_index\n",
        "    assert batch_size % num_skips == 0\n",
        "    assert num_skips <= 2 * skip_window\n",
        "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
        "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
        "    span = 2 * skip_window + 1  # o tamanho da janela de previsao do skio\n",
        "    buffer = collections.deque(maxlen=span)  # magia negra que precisei colocar, sei la pra que serve saporra mas soh funciona com isso\n",
        "    if data_index + span > len(data):\n",
        "      data_index = 0\n",
        "    buffer.extend(data[data_index:data_index + span])\n",
        "    data_index += span\n",
        "    for i in range(batch_size // num_skips):\n",
        "      context_words = [w for w in range(span) if w != skip_window]\n",
        "      words_to_use = random.sample(context_words, num_skips)\n",
        "      for j, context_word in enumerate(words_to_use):\n",
        "        batch[i * num_skips + j] = buffer[skip_window]\n",
        "        labels[i * num_skips + j, 0] = buffer[context_word]\n",
        "      if data_index == len(data):\n",
        "        buffer.extend(data[0:span])\n",
        "        data_index = span\n",
        "      else:\n",
        "        buffer.append(data[data_index])\n",
        "        data_index += 1\n",
        "    data_index = (data_index + len(data) - span) % len(data)\n",
        "    return batch, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nijGgsyja35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128 \n",
        "embedding_size = 256  # Dimensao do embedding vector. Hyperparametro que pode ser mudado e ajustado para cada modelo\n",
        "skip_window = 1  # A janela ja referida anteriormente\n",
        "num_skips = 2  # quantas vezes o label vai ser reusado\n",
        "num_sampled = 64  # Para o negative sampling, usando 64 pq eh o recomendado.\n",
        "\n",
        "valid_size = 16  # As palavras quse seram utilziadas para avaliar a similaridade.\n",
        "valid_window = 100  #janeal para a sampling das palavras de similaridade.\n",
        "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
        "\n",
        "graph = tf.Graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEMySSIOjdel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_path = os.path.dirname(os.path.realpath(sys.argv[0])) #formalidadaes para rodar o codigo, meio inutil\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "      '--log_dir',\n",
        "      type=str,\n",
        "      default=os.path.join(current_path, 'log'),\n",
        "      help='The log directory for TensorBoard summaries.')\n",
        "flags, unused_flags = parser.parse_known_args()\n",
        "\n",
        "log_dir = flags.log_dir\n",
        "\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGFWmwxSlfSC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e4fd6607-903f-4c51-90ea-5fd5612d56c8"
      },
      "source": [
        "with graph.as_default():\n",
        "    # Input data\n",
        "    with tf.name_scope('inputs'):\n",
        "        train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
        "        train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
        "        valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
        "    # Utilizando CPU pq tava fazendo no meu mac, nao tem tanto ganho assim com gpu ai deixei assim mesmo\n",
        "    with tf.device('/cpu:0'):\n",
        "        # Ver os embeddings na matriz\n",
        "        with tf.name_scope('embeddings'):\n",
        "            embeddings = tf.Variable(\n",
        "                tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
        "            embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
        "      # Constroi as variaveis para a NCE loss\n",
        "        with tf.name_scope('weights'):\n",
        "            nce_weights = tf.Variable(\n",
        "                tf.truncated_normal([vocabulary_size, embedding_size],stddev=1.0 / math.sqrt(embedding_size)))\n",
        "        with tf.name_scope('biases'):\n",
        "            nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
        "    with tf.name_scope('loss'):\n",
        "        loss = tf.reduce_mean(\n",
        "            tf.nn.nce_loss(\n",
        "                weights=nce_weights,\n",
        "                biases=nce_biases,\n",
        "                labels=train_labels,\n",
        "                inputs=embed,\n",
        "                num_sampled=num_sampled,\n",
        "                num_classes=vocabulary_size))\n",
        "    # Adiciona o valor da los\n",
        "    tf.summary.scalar('loss', loss)\n",
        "    # COnstroi o optimizer usando gradient descnete e uma learning rate de 1.0.\n",
        "    with tf.name_scope('optimizer'):\n",
        "        optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
        "    # Calcula a similaridade de cada embedding\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
        "    normalized_embeddings = embeddings / norm\n",
        "    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings,valid_dataset)\n",
        "    similarity = tf.matmul(\n",
        "        valid_embeddings, normalized_embeddings, transpose_b=True)\n",
        "    # Junta td\n",
        "    merged = tf.summary.merge_all()\n",
        "    # INicializador\n",
        "    init = tf.global_variables_initializer()\n",
        "    # Meio inutil, codigo vestigial\n",
        "    saver = tf.train.Saver()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwwe4gSalhnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_steps = 500001\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyIm-FxWlnw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.compat.v1.Session(graph=graph) as session:\n",
        "    # Gambiarra do tensorflow, abre esse writer para escrever em um arquivo para o futuro\n",
        "    writer = tf.summary.FileWriter(log_dir, session.graph)\n",
        "    # inicializa as variaveis\n",
        "    init.run()\n",
        "    print('Initialized')\n",
        "    average_loss = 0\n",
        "    for step in xrange(num_steps):\n",
        "      batch_inputs, batch_labels = generate_batch(batch_size, num_skips,\n",
        "                                                  skip_window)\n",
        "      feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
        "      # Mais uma magia negra do tensorflow, define a metadata\n",
        "      run_metadata = tf.RunMetadata()\n",
        "\n",
        "      _, summary, loss_val = session.run([optimizer, merged, loss],\n",
        "                                         feed_dict=feed_dict,\n",
        "                                         run_metadata=run_metadata)\n",
        "      average_loss += loss_val\n",
        "      writer.add_summary(summary, step)\n",
        "\n",
        "      if step == (num_steps - 1):\n",
        "        writer.add_run_metadata(run_metadata, 'step%d' % step)\n",
        "      if step % 2000 == 0:\n",
        "        if step > 0:\n",
        "          average_loss /= 2000\n",
        " \n",
        "        print('Average loss at step ', step, ': ', average_loss)\n",
        "        average_loss = 0\n",
        "\n",
        "      if step % 10000 == 0:\n",
        "        sim = similarity.eval()\n",
        "        for i in xrange(valid_size):\n",
        "          valid_word = reverse_dictionary[valid_examples[i]]\n",
        "          top_k = 8  # number of nearest neighbors\n",
        "          nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
        "          log_str = 'Nearest to %s:' % valid_word\n",
        "          print(\n",
        "              log_str,\n",
        "              ', '.join([reverse_dictionary[nearest[k]] for k in range(top_k)]))\n",
        "    final_embeddings = normalized_embeddings.eval()\n",
        "\n",
        "    with open(log_dir + '/metadata.tsv', 'w') as f:\n",
        "      for i in xrange(vocabulary_size):\n",
        "        f.write(reverse_dictionary[i] + '\\n')\n",
        "\n",
        "    saver.save(session, os.path.join(log_dir, 'model.ckpt'))\n",
        "    config = projector.ProjectorConfig()\n",
        "    embedding_conf = config.embeddings.add()\n",
        "    embedding_conf.tensor_name = embeddings.name\n",
        "    embedding_conf.metadata_path = os.path.join(log_dir, 'metadata.tsv')\n",
        "    projector.visualize_embeddings(writer, config)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mz037D5_4jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5lEdtQclobj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUPrh_A7_71z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle.dump( final_embeddings, open( \"embeds_imdb.p\", \"wb\" ) )\n",
        "pickle.dump( unused_dictionary, open( \"dictionary_imdb.p\", \"wb\" ) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtqvCmqT_78Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcd3138c-3142-4f7c-8158-00e9b2fec922"
      },
      "source": [
        "model_file = drive.CreateFile({'title' : 'embeds_imdb.p'})\n",
        "model_file.SetContentFile('./embeds_imdb.p')\n",
        "model_file.Upload()\n",
        "drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleDriveFile({'id': '17CszXuAvtdvUfxWtvlrdAUGhkW1LPPbe'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2cEg12tG-4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ff4da6b-bfce-45b9-c3a5-aad31f2af93d"
      },
      "source": [
        "model_file2 = drive.CreateFile({'title' : 'dictionary_imdb.p'})\n",
        "model_file2.SetContentFile('./dictionary_imdb.p')\n",
        "model_file2.Upload()\n",
        "drive.CreateFile({'id': model_file2.get('id')})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleDriveFile({'id': '1_uny6na4DiXoUPB7eIZBDkFNNJIjFV5y'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_ggifCRHI3H",
        "colab_type": "text"
      },
      "source": [
        "# Model stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNW_WbKNLSIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RISkLSnMH20A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd35ec5f-ec68-4d5a-bad2-5c36a392c661"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02\" -O imdb.csv\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=17CszXuAvtdvUfxWtvlrdAUGhkW1LPPbe' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=17CszXuAvtdvUfxWtvlrdAUGhkW1LPPbe\" -O embeds_imdb.p\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1_uny6na4DiXoUPB7eIZBDkFNNJIjFV5y' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1_uny6na4DiXoUPB7eIZBDkFNNJIjFV5y\" -O dictionary_imdb.p\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-21 00:14:09--  https://docs.google.com/uc?export=download&confirm=&id=1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.119.102, 108.177.119.139, 108.177.119.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.119.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0c-40-docs.googleusercontent.com/docs/securesc/819i5sl1ttha60t5qkt7442uoue3528p/fmb33lijsav734dl3qcss2f9sv33lgg0/1600647225000/00519734162681609028/05482464812705070839Z/1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02?e=download [following]\n",
            "--2020-09-21 00:14:10--  https://doc-0c-40-docs.googleusercontent.com/docs/securesc/819i5sl1ttha60t5qkt7442uoue3528p/fmb33lijsav734dl3qcss2f9sv33lgg0/1600647225000/00519734162681609028/05482464812705070839Z/1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02?e=download\n",
            "Resolving doc-0c-40-docs.googleusercontent.com (doc-0c-40-docs.googleusercontent.com)... 172.217.218.132, 2a00:1450:4013:c08::84\n",
            "Connecting to doc-0c-40-docs.googleusercontent.com (doc-0c-40-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=fuijop7js9m04&continue=https://doc-0c-40-docs.googleusercontent.com/docs/securesc/819i5sl1ttha60t5qkt7442uoue3528p/fmb33lijsav734dl3qcss2f9sv33lgg0/1600647225000/00519734162681609028/05482464812705070839Z/1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02?e%3Ddownload&hash=clft68meevgt1gdfpghqkgodabe8ovpp [following]\n",
            "--2020-09-21 00:14:10--  https://docs.google.com/nonceSigner?nonce=fuijop7js9m04&continue=https://doc-0c-40-docs.googleusercontent.com/docs/securesc/819i5sl1ttha60t5qkt7442uoue3528p/fmb33lijsav734dl3qcss2f9sv33lgg0/1600647225000/00519734162681609028/05482464812705070839Z/1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02?e%3Ddownload&hash=clft68meevgt1gdfpghqkgodabe8ovpp\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.119.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-0c-40-docs.googleusercontent.com/docs/securesc/819i5sl1ttha60t5qkt7442uoue3528p/fmb33lijsav734dl3qcss2f9sv33lgg0/1600647225000/00519734162681609028/05482464812705070839Z/1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02?e=download&nonce=fuijop7js9m04&user=05482464812705070839Z&hash=g81jo7444i8plli8v75fmdk44u0b4p5s [following]\n",
            "--2020-09-21 00:14:10--  https://doc-0c-40-docs.googleusercontent.com/docs/securesc/819i5sl1ttha60t5qkt7442uoue3528p/fmb33lijsav734dl3qcss2f9sv33lgg0/1600647225000/00519734162681609028/05482464812705070839Z/1H-xa2AqlvDfBdKN6QJVKbnP-Aw7wzZ02?e=download&nonce=fuijop7js9m04&user=05482464812705070839Z&hash=g81jo7444i8plli8v75fmdk44u0b4p5s\n",
            "Connecting to doc-0c-40-docs.googleusercontent.com (doc-0c-40-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘imdb.csv’\n",
            "\n",
            "imdb.csv                [  <=>               ]  63.14M   248MB/s    in 0.3s    \n",
            "\n",
            "2020-09-21 00:14:10 (248 MB/s) - ‘imdb.csv’ saved [66212309]\n",
            "\n",
            "--2020-09-21 00:14:12--  https://docs.google.com/uc?export=download&confirm=&id=17CszXuAvtdvUfxWtvlrdAUGhkW1LPPbe\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.218.138, 172.217.218.100, 172.217.218.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.218.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-00-a8-docs.googleusercontent.com/docs/securesc/vndt2rd5vmbe1vp76l8v749akdl2nb0s/v27ueelqlp6k52uvf5c9nac2as8k3pqb/1600647225000/00519734162681609028/00922650435918725223Z/17CszXuAvtdvUfxWtvlrdAUGhkW1LPPbe?e=download [following]\n",
            "--2020-09-21 00:14:12--  https://doc-00-a8-docs.googleusercontent.com/docs/securesc/vndt2rd5vmbe1vp76l8v749akdl2nb0s/v27ueelqlp6k52uvf5c9nac2as8k3pqb/1600647225000/00519734162681609028/00922650435918725223Z/17CszXuAvtdvUfxWtvlrdAUGhkW1LPPbe?e=download\n",
            "Resolving doc-00-a8-docs.googleusercontent.com (doc-00-a8-docs.googleusercontent.com)... 172.217.218.132, 2a00:1450:4013:c08::84\n",
            "Connecting to doc-00-a8-docs.googleusercontent.com (doc-00-a8-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=ld7rsku97fp8m&continue=https://doc-00-a8-docs.googleusercontent.com/docs/securesc/vndt2rd5vmbe1vp76l8v749akdl2nb0s/v27ueelqlp6k52uvf5c9nac2as8k3pqb/1600647225000/00519734162681609028/00922650435918725223Z/17CszXuAvtdvUfxWtvlrdAUGhkW1LPPbe?e%3Ddownload&hash=c1kbse6v3qr4rg6d5bd2b7v2lir5ovbv [following]\n",
            "--2020-09-21 00:14:13--  https://docs.google.com/nonceSigner?nonce=ld7rsku97fp8m&continue=https://doc-00-a8-docs.googleusercontent.com/docs/securesc/vndt2rd5vmbe1vp76l8v749akdl2nb0s/v27ueelqlp6k52uvf5c9nac2as8k3pqb/1600647225000/00519734162681609028/00922650435918725223Z/17CszXuAvtdvUfxWtvlrdAUGhkW1LPPbe?e%3Ddownload&hash=c1kbse6v3qr4rg6d5bd2b7v2lir5ovbv\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.218.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-00-a8-docs.googleusercontent.com/docs/securesc/vndt2rd5vmbe1vp76l8v749akdl2nb0s/v27ueelqlp6k52uvf5c9nac2as8k3pqb/1600647225000/00519734162681609028/00922650435918725223Z/17CszXuAvtdvUfxWtvlrdAUGhkW1LPPbe?e=download&nonce=ld7rsku97fp8m&user=00922650435918725223Z&hash=ib0lp2uc2h0dss16ikkjo0uo58ng74vf [following]\n",
            "--2020-09-21 00:14:13--  https://doc-00-a8-docs.googleusercontent.com/docs/securesc/vndt2rd5vmbe1vp76l8v749akdl2nb0s/v27ueelqlp6k52uvf5c9nac2as8k3pqb/1600647225000/00519734162681609028/00922650435918725223Z/17CszXuAvtdvUfxWtvlrdAUGhkW1LPPbe?e=download&nonce=ld7rsku97fp8m&user=00922650435918725223Z&hash=ib0lp2uc2h0dss16ikkjo0uo58ng74vf\n",
            "Connecting to doc-00-a8-docs.googleusercontent.com (doc-00-a8-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/x-pascal]\n",
            "Saving to: ‘embeds_imdb.p’\n",
            "\n",
            "embeds_imdb.p           [ <=>                ]  39.06M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-09-21 00:14:13 (328 MB/s) - ‘embeds_imdb.p’ saved [40960162]\n",
            "\n",
            "--2020-09-21 00:14:14--  https://docs.google.com/uc?export=download&confirm=&id=1_uny6na4DiXoUPB7eIZBDkFNNJIjFV5y\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.218.138, 172.217.218.113, 172.217.218.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.218.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0s-cc-docs.googleusercontent.com/docs/securesc/718etutbmb4ggfmqg1fmn9k7e1g2hgv9/d4d3m12dcuep7fvlov1gcdter0288dn9/1600647225000/00519734162681609028/03518781031962181303Z/1_uny6na4DiXoUPB7eIZBDkFNNJIjFV5y?e=download [following]\n",
            "--2020-09-21 00:14:14--  https://doc-0s-cc-docs.googleusercontent.com/docs/securesc/718etutbmb4ggfmqg1fmn9k7e1g2hgv9/d4d3m12dcuep7fvlov1gcdter0288dn9/1600647225000/00519734162681609028/03518781031962181303Z/1_uny6na4DiXoUPB7eIZBDkFNNJIjFV5y?e=download\n",
            "Resolving doc-0s-cc-docs.googleusercontent.com (doc-0s-cc-docs.googleusercontent.com)... 172.217.218.132, 2a00:1450:4013:c08::84\n",
            "Connecting to doc-0s-cc-docs.googleusercontent.com (doc-0s-cc-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=ghbel1gj9fhkq&continue=https://doc-0s-cc-docs.googleusercontent.com/docs/securesc/718etutbmb4ggfmqg1fmn9k7e1g2hgv9/d4d3m12dcuep7fvlov1gcdter0288dn9/1600647225000/00519734162681609028/03518781031962181303Z/1_uny6na4DiXoUPB7eIZBDkFNNJIjFV5y?e%3Ddownload&hash=0nokt8n3sm11g756t5gl003llnd882kp [following]\n",
            "--2020-09-21 00:14:14--  https://docs.google.com/nonceSigner?nonce=ghbel1gj9fhkq&continue=https://doc-0s-cc-docs.googleusercontent.com/docs/securesc/718etutbmb4ggfmqg1fmn9k7e1g2hgv9/d4d3m12dcuep7fvlov1gcdter0288dn9/1600647225000/00519734162681609028/03518781031962181303Z/1_uny6na4DiXoUPB7eIZBDkFNNJIjFV5y?e%3Ddownload&hash=0nokt8n3sm11g756t5gl003llnd882kp\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.218.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-0s-cc-docs.googleusercontent.com/docs/securesc/718etutbmb4ggfmqg1fmn9k7e1g2hgv9/d4d3m12dcuep7fvlov1gcdter0288dn9/1600647225000/00519734162681609028/03518781031962181303Z/1_uny6na4DiXoUPB7eIZBDkFNNJIjFV5y?e=download&nonce=ghbel1gj9fhkq&user=03518781031962181303Z&hash=3q3hcssge162gi2luvtr3pentbjkc14d [following]\n",
            "--2020-09-21 00:14:14--  https://doc-0s-cc-docs.googleusercontent.com/docs/securesc/718etutbmb4ggfmqg1fmn9k7e1g2hgv9/d4d3m12dcuep7fvlov1gcdter0288dn9/1600647225000/00519734162681609028/03518781031962181303Z/1_uny6na4DiXoUPB7eIZBDkFNNJIjFV5y?e=download&nonce=ghbel1gj9fhkq&user=03518781031962181303Z&hash=3q3hcssge162gi2luvtr3pentbjkc14d\n",
            "Connecting to doc-0s-cc-docs.googleusercontent.com (doc-0s-cc-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 793553 (775K) [text/x-pascal]\n",
            "Saving to: ‘dictionary_imdb.p’\n",
            "\n",
            "dictionary_imdb.p   100%[===================>] 774.95K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2020-09-21 00:14:15 (148 MB/s) - ‘dictionary_imdb.p’ saved [793553/793553]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVWTM_19JCVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "embeds = pickle.load(open(\"embeds_imdb.p\",\"rb\"))\n",
        "imdb_dict = pickle.load(open(\"dictionary_imdb.p\",\"rb\"))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPR767WyJdWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dados = pd.read_csv('imdb.csv')\n",
        "fix_break = lambda x: x.replace(\"<br />\",\" <br/> \")\n",
        "fix_dots = lambda x: x.replace(\".\",\" . \")\n",
        "fix_comma = lambda x: x.replace(\",\",\" , \")\n",
        "fix_brackets1 = lambda x: x.replace(\"(\",\" ( \")\n",
        "fix_brackets2 = lambda x: x.replace(\")\",\" ) \")\n",
        "fix_dash = lambda x: x.replace(\"-\",\" - \")     \n",
        "fix_excl = lambda x: x.replace(\"!\",\" ! \")     \n",
        "dados.review = dados.review.apply(fix_break)\n",
        "dados.review = dados.review.apply(fix_dots)\n",
        "dados.review = dados.review.apply(fix_comma)\n",
        "dados.review = dados.review.apply(fix_brackets1)\n",
        "dados.review = dados.review.apply(fix_brackets2)\n",
        "dados.review = dados.review.apply(fix_excl)\n",
        "dados.review = dados.review.apply(fix_dash)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEvjvDvUlz_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self,size,hidden_size,num_layers):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size = size,hidden_size = hidden_size, num_layers = 1, bidirectional = True)\n",
        "        self.output_layer = nn.Linear(2*hidden_size,2)\n",
        "        self.activation = F.relu\n",
        "    def forward(self,inputs,seq_len):\n",
        "        import pdb;pdb.set_trace()\n",
        "        packed_input = pack_padded_sequence(inputs.float(),seq_len,enforce_sorted = False)\n",
        "        _, (h_n, c_n) = self.lstm(packed_input)\n",
        "        lstm_output = torch.cat([h_n[-1], h_n[-2]], -1)\n",
        "        output = self.output_layer(self.activation(lstm_output))\n",
        "        return output\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouFRMBkUnaoQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28376c34-8543-4c16-9e43-a221e636ef8b"
      },
      "source": [
        "!pip install ujson"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ujson in /usr/local/lib/python3.6/dist-packages (3.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h7SfDBXzU4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dill as dill\n",
        "import os\n",
        "import ujson\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import json\n",
        "from smart_open import open\n",
        "from sklearn.utils import shuffle\n",
        "import msgpack\n",
        "import io\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import torch\n",
        "import pickle\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import random\n",
        "\n",
        "from functools import lru_cache\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTvHGn5Iql8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_embeddings(lookup,word_dict,words):\n",
        "    #import pdb;pdb.set_trace()\n",
        "    string_list = words.split(\" \")\n",
        "    vectors = []\n",
        "    for x in string_list:\n",
        "        if x in word_dict.keys():\n",
        "            vectors.append(lookup[word_dict[x]])\n",
        "        else:\n",
        "            vectors.append(lookup[word_dict[\"UNK\"]])\n",
        "    return np.array(vectors)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba7Svd2GRk4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import io\n",
        "from collections import Counter\n",
        "import pickle\n",
        "from smart_open import open\n",
        "import msgpack\n",
        "#import msgpack_numpy as m\n",
        "#m.patch()\n",
        "def pandas_to_bytes(df):\n",
        "    buf = io.BytesIO()\n",
        "    df.to_msgpack(path_or_buf = buf)\n",
        "    return buf.getvalue()\n",
        "def bytes_to_pandas(content):\n",
        "    buf = io.BytesIO(content)\n",
        "    return pd.read_msgpack(buf)\n",
        "def tensor_to_bytes(tensor):\n",
        "    buf = io.BytesIO()\n",
        "    torch.save(tensor, buf)\n",
        "    return buf.getvalue()\n",
        "def bytes_to_tensor(content):\n",
        "    buf = io.BytesIO(content)\n",
        "    return torch.load(buf)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSnbxyyKSVtH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "c884dfe9-8ef1-4dd4-a4db-4294131e442c"
      },
      "source": [
        "\"\"\"\n",
        "data = dados\n",
        "train = []\n",
        "test = []\n",
        "fname2 = f'imdb_tensors_train.msgpack.gz'\n",
        "fname3 = f'imdb_tensors_test.msgpack.gz'\n",
        "g = open(fname2, 'wb')\n",
        "h = open(fname3, 'wb')\n",
        "for ind,row in tqdm(dados.iterrows()):\n",
        "    txt = convert_embeddings(embeds,imdb_dict,row.review)\n",
        "    if row.sentiment == \"positive\":\n",
        "        label = 1\n",
        "\n",
        "    else:\n",
        "        label = 0\n",
        "    if ind%5==0:\n",
        "        msgpack.dump([tensor_to_bytes(txt),label],h)\n",
        "    else:\n",
        "        msgpack.dump([tensor_to_bytes(txt),label],g)\n",
        "\n",
        "g.close()\n",
        "h.close()\n",
        "\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndata = dados\\ntrain = []\\ntest = []\\nfname2 = f\\'imdb_tensors_train.msgpack.gz\\'\\nfname3 = f\\'imdb_tensors_test.msgpack.gz\\'\\ng = open(fname2, \\'wb\\')\\nh = open(fname3, \\'wb\\')\\nfor ind,row in tqdm(dados.iterrows()):\\n    txt = convert_embeddings(embeds,imdb_dict,row.review)\\n    if row.sentiment == \"positive\":\\n        label = 1\\n\\n    else:\\n        label = 0\\n    if ind%5==0:\\n        msgpack.dump([tensor_to_bytes(txt),label],h)\\n    else:\\n        msgpack.dump([tensor_to_bytes(txt),label],g)\\n\\ng.close()\\nh.close()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YboT1BYkk3g8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "67e0f627-d35b-4a53-9422-bbf296c35e02"
      },
      "source": [
        "\"\"\"from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\"\"\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'from pydrive.auth import GoogleAuth\\nfrom pydrive.drive import GoogleDrive\\nfrom google.colab import auth\\nfrom oauth2client.client import GoogleCredentials\\nauth.authenticate_user()\\ngauth = GoogleAuth()\\ngauth.credentials = GoogleCredentials.get_application_default()\\ndrive = GoogleDrive(gauth)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA6OiS2MlAmp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "75bd430d-baeb-41ab-b94a-3e0690ce0fdf"
      },
      "source": [
        "\"\"\"\n",
        "model_file = drive.CreateFile({'title' : 'imdb_tensors.msgpack.gz'})\n",
        "model_file.SetContentFile('./imdb_tensors.msgpack.gz')\n",
        "model_file.Upload()\n",
        "drive.CreateFile({'id': model_file.get('id')})\"\"\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nmodel_file = drive.CreateFile({'title' : 'imdb_tensors.msgpack.gz'})\\nmodel_file.SetContentFile('./imdb_tensors.msgpack.gz')\\nmodel_file.Upload()\\ndrive.CreateFile({'id': model_file.get('id')})\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av-FzKSPliaQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2914567a-8d95-41e2-8832-cf8baf3980f3"
      },
      "source": [
        "!ls -l --block-size=MB"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 130MB\n",
            "-rw-r--r-- 1 root root  1MB Sep 21 00:14 dictionary_imdb.p\n",
            "-rw-r--r-- 1 root root 41MB Sep 21 00:14 embeds_imdb.p\n",
            "-rw-r--r-- 1 root root 67MB Sep 21 00:14 imdb.csv\n",
            "drwxr-xr-x 1 root root  1MB Sep 16 16:29 sample_data\n",
            "-rw-r--r-- 1 root root 11MB Sep 21 00:05 test_best_model.pth\n",
            "-rw-r--r-- 1 root root 11MB Sep 21 00:05 test_last_model.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BAsm5RFig5B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b201e32d-d996-455d-f04f-84beeecc3033"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dictionary_imdb.p  imdb.csv\ttest_best_model.pth\n",
            "embeds_imdb.p\t   sample_data\ttest_last_model.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW6LBsKcnYIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImdbDataset(Dataset):\n",
        "    def __init__(self, num_lines, train=False):\n",
        "        self.fname = f'imdb_tensors_train.msgpack.gz' if train else f'imdb_tensors_test.msgpack.gz'\n",
        "        self.len = 0\n",
        "        #import pdb;pdb.set_trace()\n",
        "        with open(self.fname, 'rb') as g:\n",
        "            tmp = msgpack.Unpacker(g)\n",
        "            for n,i in tqdm(enumerate(tmp)):\n",
        "                self.len+=1\n",
        "        self.f= open(self.fname, 'rb')\n",
        "        self.sections = msgpack.Unpacker(self.f)\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    def __getitem__(self, item):\n",
        "        for n, section in enumerate(self.sections):\n",
        "            txt = bytes_to_tensor(section[0])\n",
        "            label = section[1]\n",
        "            break     \n",
        "        return (txt,label)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUJGq7TFwhil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImdbDataset_v2(Dataset):\n",
        "    def __init__(self,dados, num_lines, train=False):\n",
        "        self.len = 0\n",
        "        if train:\n",
        "            self.data = dados.sample(frac=1).reset_index(drop=True)\n",
        "        else:\n",
        "            self.data = dados.iloc[:10000].sample(frac=1).reset_index(drop=True)\n",
        "        #import pdb;pdb.set_trace()\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, item):\n",
        "        tmp = self.data.iloc[item]\n",
        "        txt = convert_embeddings(embeds,imdb_dict,tmp.review)\n",
        "        if tmp.sentiment == \"positive\":\n",
        "            label = 1\n",
        "\n",
        "        else:\n",
        "            label = 0\n",
        "        return (txt,label)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3BouJ_7jx2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_batch(batch):\n",
        "    #import pdb;pdb.set_trace()\n",
        "    element_vectors, targets = zip(*batch)\n",
        "    num_elements = torch.tensor([len(c) for c in element_vectors], dtype=torch.long)#long\n",
        "    element_tensors =[torch.tensor(x) for x in element_vectors] \n",
        "    tensor_out = pad_sequence(element_tensors)\n",
        "    targets = torch.tensor(targets)\n",
        "    return (\n",
        "        (tensor_out, num_elements),\n",
        "        targets\n",
        "    )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeWuKfygrDSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seeds(worker_id):\n",
        "    seed = torch.initial_seed() % 2 ** 31\n",
        "    np.random.seed(seed + 1)\n",
        "    random.seed(seed + 2)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IomiRoE3Pbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dill as dill\n",
        "import os\n",
        "import ujson\n",
        "BASE_PATH = \"/home/ec2-user/SageMaker/DataTeamExperiments/Dasa-Impar-Embedding\"\n",
        "OBSERVER_PATH = os.path.join(BASE_PATH, \"Model_Results\")\n",
        "TRAIN = \"train\"\n",
        "VALIDATION = \"validation\"\n",
        "TEST = \"test\"\n",
        "\n",
        "\n",
        "def pad_label(tensor, size):\n",
        "    return torch.cat((tensor,(size[1]-1)*torch.ones([size[0]-tensor.size(0)]).long().cuda()),0)\n",
        "def pad_outs(tensor,size):\n",
        "    return torch.cat((tensor, torch.rand([(size - tensor.size(0)),tensor.size(1)]).cuda()))\n",
        "\n",
        "class SummaryWriter:\n",
        "    def __init__(self, dir, model_desc=''):\n",
        "        if not os.path.exists(dir):\n",
        "            os.makedirs(dir)\n",
        "\n",
        "        self.dir = dir\n",
        "        self.dict = {}\n",
        "        if model_desc:\n",
        "            self.dict['about'] = model_desc\n",
        "\n",
        "    def add_scalar(self, tag, value, key):\n",
        "        if tag not in self.dict:\n",
        "            self.dict[tag] = {}\n",
        "\n",
        "        self.dict[tag][key] = value\n",
        "\n",
        "    def commit(self):\n",
        "        with open(os.path.join(self.dir, \"writer.json\"), \"w+\") as f:\n",
        "            ujson.dump(self.dict, f)\n",
        "            \n",
        "def set_seeds(worker_id):\n",
        "    seed = torch.initial_seed() % 2 ** 31\n",
        "    np.random.seed(seed + 1)\n",
        "    random.seed(seed + 2)\n",
        "    \n",
        "def create_exp_folder(base_path):\n",
        "    results = sorted(filter(lambda f: not f.startswith(\".\"), os.listdir(base_path)))\n",
        "    if len(results) == 0:\n",
        "        exp_id = 1\n",
        "    else:\n",
        "        exp_id = len(results) + 1\n",
        "    exp_id = str(exp_id)\n",
        "\n",
        "    os.mkdir(os.path.join(base_path, exp_id))\n",
        "    return exp_id\n",
        "\n",
        "\n",
        "def layer_norm_normalization(data: torch.tensor, dim=-1):\n",
        "    \"\"\"\n",
        "    Normalize outputs to norm=1.0\n",
        "    \"\"\"\n",
        "    return data / data.norm(dim=dim, keepdim=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C32KHxm3Phg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn.functional import one_hot\n",
        "from tqdm import autonotebook, tqdm_notebook as tqdm\n",
        "\n",
        "\n",
        "def train(model, loss_fn, n_epochs, patience, batch_size, lr, exp_id, num_lines=None):\n",
        "    #writer = SummaryWriter(os.path.join(OBSERVER_PATH, exp_id), str(model))\n",
        "    #last_model_path = os.path.join(OBSERVER_PATH, exp_id, \"test_last_model.pth\")\n",
        "    #best_model_path = os.path.join(OBSERVER_PATH, exp_id, \"test_best_model.pth\")\n",
        "    best_model_path = \"test_best_model.pth\"\n",
        "    last_model_path = \"test_last_model.pth\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    try:\n",
        "        #import pdb;pdb.set_trace()\n",
        "        train_dataset = ImdbDataset_v2(dados,num_lines, train=True)\n",
        "        val_dataset = ImdbDataset_v2(dados,num_lines)\n",
        "    #    if len(train_dataset) % batch_size == 1 or len(val_dataset) % batch_size == 1:\n",
        "    #        raise Exception(\"Last batch size equal to 1 will cause error\")\n",
        "    #    sampler = RandomSampler(int(len(train_dataset) / 5))\n",
        "        train_dataloader = DataLoader(train_dataset,\n",
        "                                      batch_size=batch_size, \n",
        "                                      collate_fn=pad_batch,\n",
        "                                      worker_init_fn=set_seeds,\n",
        "                                      )\n",
        "        val_dataloader = DataLoader(val_dataset,\n",
        "                                    batch_size=batch_size, \n",
        "                                    collate_fn=pad_batch, \n",
        "                                    worker_init_fn=set_seeds)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        epochs = range(1, n_epochs + 1)\n",
        "        best_loss = np.inf\n",
        "        epochs_since_best = 0\n",
        "\n",
        "        for epoch in epochs:\n",
        "            epoch_dataloader = train_dataloader\n",
        "\n",
        "\n",
        "            train_info = run_epoch(\"train\", epoch, model, epoch_dataloader, loss_fn, optimizer, batch_size,\n",
        "                                   extra_metrics=[accuracy])\n",
        "            val_info = run_epoch(\"validation\", epoch, model, val_dataloader, loss_fn, optimizer, batch_size,\n",
        "                                 extra_metrics=[accuracy])\n",
        "            \"\"\"\n",
        "            if val_info[\"Gini\"] > best_loss:\n",
        "                best_loss = val_info[\"Gini\"]\n",
        "                torch.save(model, best_model_path)\n",
        "                epochs_since_best = 0\n",
        "                print(\"Saving this version\")\n",
        "            \"\"\"\n",
        "            if not torch.isnan(torch.tensor(val_info[\"loss\"])):\n",
        "                if val_info[\"loss\"] < best_loss:\n",
        "                    best_loss = val_info[\"loss\"]\n",
        "                    torch.save(model, best_model_path)\n",
        "                    epochs_since_best = 0\n",
        "        #            with open('s3://data-nexa-sets/pdf/distance_model_char.pth', 'wb') as f:\n",
        "        #                torch.save(model.state_dict(), f)\n",
        "                else:\n",
        "                    epochs_since_best += 1\n",
        "            else:\n",
        "                epochs_since_best += 1\n",
        "            torch.save(model, last_model_path, pickle_module=dill)\n",
        "            if epochs_since_best > patience:\n",
        "                break\n",
        "\n",
        "            #writer.commit()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        torch.cuda.empty_cache()  "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtLsyJCC5Nws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def accuracy(outputs, targets):\n",
        "    #import pdb;pdb.set_trace()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    target_mask = (torch.arange(2).unsqueeze(0).expand(targets.size(0), -1).to(device) == targets.unsqueeze(1).to(device)).float()\n",
        "    lambdas = outputs.exp()\n",
        "    prob_expo = 1-(-lambdas/2).exp()\n",
        "    soft = prob_expo.squeeze(1).round()\n",
        "    comp = targets.to(device) == soft\n",
        "    return float((comp.float().sum())/len(comp))\n",
        "def accuracy(outs, targets):\n",
        "    #import pdb;pdb.set_trace()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    soft = torch.softmax(outs,dim = 1)\n",
        "    comp = targets.to(device) == torch.argmax(soft,1)\n",
        "    return float((comp.float().sum())/len(comp))\n",
        "#def accuracy(outs, targets):\n",
        "    #import pdb;pdb.set_trace()\n",
        "#    return abs(float((targets.unsqueeze(1).to(device)-outs).mean()))\n",
        "def log_softmax(data):\n",
        "    prob_numerators = torch.exp(data)\n",
        "    prob_denominators = prob_numerators.sum(-1).unsqueeze(-1)\n",
        "    return (data - torch.log(prob_denominators))\n",
        "def numpy_ewma_vectorized(data, window=40):\n",
        "\n",
        "    data = np.array(data)\n",
        "    alpha = 2 /(window + 1.0)\n",
        "    alpha_rev = 1-alpha\n",
        "\n",
        "    scale = 1/alpha_rev\n",
        "    n = data.shape[0]\n",
        "    if n > 4*window:\n",
        "        n = 4 * window\n",
        "        data = data[-n:]\n",
        "\n",
        "    r = np.arange(n)\n",
        "    scale_arr = scale**r\n",
        "\n",
        "    mult = data*scale_arr\n",
        "    out = mult.sum() / scale_arr.sum()\n",
        "    return out"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrZTkwYF5Wxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def gini_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    criteria_sort = y_pred.argsort()[::-1]\n",
        "    observed_sort = y_true.argsort()[::-1]\n",
        "    n = len(y_true)\n",
        "    area = y_true[criteria_sort] * (n - np.arange(0, n))\n",
        "    area2 = y_true[observed_sort] * (n - np.arange(0, n))\n",
        "    return (area.sum() - n * y_true.sum() / 2) / (area2.sum() - n * y_true.sum() / 2)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1J9pENU5NzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import partial\n",
        "WMA_WINDOW = 1000\n",
        "\n",
        "def run_epoch(phase, epoch, model, dataloader, loss_fn, optimizer, batch_size, scheduler=None, extra_metrics=None, device=None,\n",
        "              writer=None):\n",
        "    training = phase == \"train\"\n",
        "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch} - {phase}\")\n",
        "    if extra_metrics is None:\n",
        "        extra_metrics = {}\n",
        "    elif isinstance(extra_metrics, list):\n",
        "        extra_metrics_tmp = {}\n",
        "        for metric in extra_metrics:\n",
        "            if isinstance(metric, tuple):\n",
        "                metric_name, metric_fn = metric\n",
        "                extra_metrics_tmp[metric_name] = metric_fn\n",
        "            else:\n",
        "                extra_metrics_tmp[metric.__name__] = metric\n",
        "        extra_metrics = extra_metrics_tmp\n",
        "\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    elif isinstance(device, str):\n",
        "        device = torch.device(device)\n",
        "    \n",
        "    model = model.to(device)\n",
        "\n",
        "    if training:\n",
        "        model.train()\n",
        "        mean_fn = partial(numpy_ewma_vectorized, window=int(WMA_WINDOW/batch_size + 1))\n",
        "    else:\n",
        "        model.eval()\n",
        "        mean_fn = np.mean\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    losses = []\n",
        "    extra_metrics_values = {metric_name: [] for metric_name, _ in extra_metrics.items()}\n",
        "    for i, data in enumerate(progress_bar):\n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(training):\n",
        "            elements_data, y = data#\n",
        "            results = model(elements_data[0].to(device),elements_data[1].to(device))#\n",
        "            #import pdb;pdb.set_trace()\n",
        "            #print(results)\n",
        "            loss = loss_fn(results, y.long().to(device))#\n",
        "            if training:\n",
        "                if not torch.isnan(loss):\n",
        "                    #loss = torch.sqrt(loss)\n",
        "                    loss.backward()#retain_graph=True)#\n",
        "                else:\n",
        "                    continue\n",
        "                    import pdb;pdb.set_trace()\n",
        "                optimizer.step()#\n",
        "                if scheduler is not None:\n",
        "                    scheduler.step()\n",
        "            losses.append(loss.item())#\n",
        "            progress_bar_dict = {f\"{phase} loss\": mean_fn(losses)}\n",
        "            for extra_metric_name, extra_metric_fn in extra_metrics.items():\n",
        "                value_tmp = extra_metric_fn(results,y)#\n",
        "                extra_metrics_values[extra_metric_name].append(value_tmp)\n",
        "                progress_bar_dict[f\"{phase} {extra_metric_name}\"] =mean_fn(extra_metrics_values[extra_metric_name])\n",
        "            progress_bar.set_postfix(progress_bar_dict)\n",
        "    #tot_soft = torch.softmax(total_r,axis = 1)\n",
        "    mean_loss = mean_fn(losses)\n",
        "    info = {\"loss\": mean_loss}\n",
        "    for extra_metric_name, _ in extra_metrics.items():\n",
        "        info[extra_metric_name] = mean_fn(extra_metrics_values[extra_metric_name])\n",
        "    #import pdb;pdb.set_trace()\n",
        "    #lambdas = total_r.exp()\n",
        "    #prob_expo = 1-(-lambdas/2).exp()    \n",
        "    #scr = gini_score(total_y.cpu().detach().numpy(), prob_expo.squeeze(1).cpu().detach().numpy())#tot_soft[:,1].cpu().detach().numpy())\n",
        "    #print(\"Gini Score: \", scr)\n",
        "    #if scr<0:\n",
        "        #import pdb;pdb.set_trace()\n",
        "    #info['Gini'] = scr\n",
        "    if writer is not None:\n",
        "        for metric_name, metric_mean_value in info.items():\n",
        "            writer.add_scalar(f\"{phase}.{metric_name}\", metric_mean_value, epoch)\n",
        "    return info\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgo_-vsMGK-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "import torch.nn.functional as F\n",
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self,size,hidden_size,num_layers):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size = size,hidden_size = hidden_size, num_layers = num_layers, bidirectional = True)\n",
        "        self.output_layer = nn.Linear(2*hidden_size,2)\n",
        "        self.activation = F.relu\n",
        "    def forward(self,inputs,seq_len):\n",
        "        #import pdb;pdb.set_trace()\n",
        "        packed_input = pack_padded_sequence(inputs.float(),seq_len,enforce_sorted = False)\n",
        "        tmp, (h_n, c_n) = self.lstm(packed_input)\n",
        "        lstm_output = torch.cat([h_n[-1], h_n[-2]], -1)\n",
        "        output = self.output_layer(lstm_output)\n",
        "        return output\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_KarH2JoSis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "import torch.nn.functional as F\n",
        "class AttentionLSTM(nn.Module):\n",
        "    def __init__(self,size,hidden_size,num_layers,d_a=250,r1 = 10):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size = size,hidden_size = hidden_size, num_layers = num_layers, bidirectional = True)\n",
        "        self.output_layer = nn.Linear(2*hidden_size,2)\n",
        "        self.activation = F.relu\n",
        "\n",
        "        self.att = torch.nn.Linear(size*2,d_a) #WS1\n",
        "        self.att.bias.data.fill_(0) #bias zerao\n",
        "        self.ws2 = torch.nn.Linear(d_a,r1) #Ws2, if using multiple attention heads\n",
        "        self.ws2.bias.data.fill_(0)\n",
        "        self.r1 = r1\n",
        "    def masked_softmax(self,vector,mask,dim=0): #for the attention module\n",
        "        for k in range(vector.size(1)):\n",
        "            vec = torch.cat((torch.softmax(vector[:mask[k],k,:] ,axis = dim),torch.zeros([vector.size(0)-mask[k],self.r1]).to(device)))\n",
        "            vec = vec.unsqueeze(1)\n",
        "            try:\n",
        "                out = torch.cat((out,vec),axis=1)\n",
        "            except:\n",
        "                out = vec\n",
        "        return out\n",
        "    def forward(self,inputs,seq_len):\n",
        "        #import pdb;pdb.set_trace()\n",
        "        #packed_input = pack_padded_sequence(inputs.float(),seq_len,enforce_sorted = False)\n",
        "        #tmp, (h_n, c_n) = self.lstm(packed_input)\n",
        "        tmp = self.lstm(inputs.float())\n",
        "\n",
        "        phrase_1 = F.relu(self.att(tmp[0]))\n",
        "        phrase_2 = self.ws2(phrase_1)\n",
        "        phrase_2 = self.masked_softmax(phrase_2,seq_len)\n",
        "        attention_phrase = phrase_2.transpose(0,1)\n",
        "        attention_phrase = attention_phrase.transpose(1,2)\n",
        "        sentence_embeddings = attention_phrase@(tmp[0].transpose(0,1))\n",
        "        avg_sentence_embeddings = torch.sum(sentence_embeddings,1)/self.r1\n",
        "\n",
        "\n",
        "\n",
        "        #lstm_output = torch.cat([h_n[-1], h_n[-2]], -1)\n",
        "        output = self.output_layer(avg_sentence_embeddings)\n",
        "        return output"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SWz0i9X5N4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = ensemble_model(20,2,1)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "model = AttentionLSTM(size = 256,hidden_size=256,num_layers = 1)\n",
        "model.to(device)\n",
        "#with open('s3://data-nexa-sets/pdf/qloss_model.pth', 'rb') as f:\n",
        "#    model.load_state_dict(torch.load(f, map_location=device))\n",
        "model.train()\n",
        "\n",
        "\n",
        "patience = 10\n",
        "batch_size = 8\n",
        "lr = 0.001\n",
        "\n",
        "closs = nn.CrossEntropyLoss()\n",
        "#floss = FocalLoss(gamma = 2.0)#gamma=2.0)\n",
        "mseloss = torch.nn.MSELoss()\n",
        "loss_fn = closs\n",
        "n_epochs = 30\n",
        "num_lines = None\n",
        "\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUGut-XlmNvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390,
          "referenced_widgets": [
            "9a906c7aeb6148f499824b4e764cebc1",
            "1c13cbcfb6c54b789779707d7a40fedb",
            "75e8898d88754091841c356a7db5a923",
            "d698aebe70134fd196d34d1a2e9bc9af",
            "6af588fbe5ad4e7aaa7f78444bf01ab4",
            "1f866b4389034af5ae0e72fb133e9fdb",
            "f936760ef19145e69b47134698a34ad8",
            "6fd4f11af5c542d79188da351a69c657"
          ]
        },
        "outputId": "0d7c0e3b-a218-454d-91bf-12d8dbedc3d8"
      },
      "source": [
        "train(model, loss_fn, n_epochs, patience, batch_size, lr, \"01\", num_lines)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a906c7aeb6148f499824b4e764cebc1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1 - train', max=6250.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-32208199079a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-86912d82494d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, n_epochs, patience, batch_size, lr, exp_id, num_lines)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             train_info = run_epoch(\"train\", epoch, model, epoch_dataloader, loss_fn, optimizer, batch_size,\n\u001b[0;32m---> 41\u001b[0;31m                                    extra_metrics=[accuracy])\n\u001b[0m\u001b[1;32m     42\u001b[0m             val_info = run_epoch(\"validation\", epoch, model, val_dataloader, loss_fn, optimizer, batch_size,\n\u001b[1;32m     43\u001b[0m                                  extra_metrics=[accuracy])\n",
            "\u001b[0;32m<ipython-input-23-8623a123a827>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(phase, epoch, model, dataloader, loss_fn, optimizer, batch_size, scheduler, extra_metrics, device, writer)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;31m#loss = torch.sqrt(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#retain_graph=True)#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ON1bXP64BUP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b72fb8b4-6f60-42c9-8e91-e3603a23420c"
      },
      "source": [
        "1+1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD7iFNDN_SjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}